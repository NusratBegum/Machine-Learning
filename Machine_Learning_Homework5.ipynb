{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6h0uFaqpjzQTpf2XpJdQh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NusratBegum/Machine-Learning/blob/main/Machine_Learning_Homework5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 5.1\n",
        "1. Using (https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/) as reference,\n",
        "use Naïve Bayes classification to perform classification validation on the test dataset. Change the dataset to the famous Iris dataset (https://archive.ics.uci.edu/dataset/53/iris)\n",
        "\n",
        "> Task\n",
        "* Use 5-fold cross validation (80:20) and Naïve Bayes classification algorithm to predict the test dataset.\n",
        "* Determine the confusion matrix, precision, recall and F1 score of the method.\n",
        "\n",
        "> Note: you will have to change class label to a numerical value to ease the computation.\n",
        "\n",
        "\n",
        "2. Compare the result when predicting with sklearn GaussianNB library\n",
        "(https://www.kaggle.com/code/nizamudma/iris-data-classification-using-naive-bayes)"
      ],
      "metadata": {
        "id": "_ZyPR7_Ez0Mu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAyKqOw7zTk7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 5.2\n",
        "\n",
        "1. Using (https://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-pythonfrom-scratch/) as reference, use KNN classification algorithm to perform classification on the test\n",
        "dataset. Change the dataset to the famous Iris dataset (https://archive.ics.uci.edu/dataset/53/iris).\n",
        "\n",
        "> Note: you will have to change class label to a numerical value to ease the computation.\n",
        "> Task:\n",
        "* Use 5-fold cross validation (80:20) to predict the test dataset.\n",
        "* Determine the confusion matrix, precision, recall and F1 score of the method. Use Minkowski and Euclidean distance.\n",
        "* Determine the value of k based on ROC curve. Does it mean that higher value of k will improve performance?\n",
        "\n",
        "2. Compare the results when predicting with sklearn KNeighborsClassifier library\n",
        "(https://www.kaggle.com/code/skalskip/iris-data-visualization-and-knn-classification/notebook) and\n",
        "(https://www.tutorialspoint.com/scikit_learn/scikit_learn_kneighbors_classifier.htm)\n",
        "\n"
      ],
      "metadata": {
        "id": "bdbIWiN_z49J"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LLYoQ_Nlz52a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 5.3\n",
        "\n",
        "1. Using (https://machinelearningmastery.com implement-decision-tree-algorithm-scratch-python/) as\n",
        "reference, replace this with Iris dataset (https://archive.ics.uci.edu/dataset/53/iris) and heart disease\n",
        "dataset (https://archive.ics.uci.edu/dataset/45/heart+disease).\n",
        "\n",
        "> Task:\n",
        "* Use 5-fold cross validation (80:20) and decision tree with Gini (CART) <font color='lightgreen'>[and Information Gain (ID3 or C4.5) for extra credit]</font> to predict the test dataset.\n",
        "* Classify the dataset and Determine the confusion matrix, precision, recall and F1 score of the method.\n",
        "* Determine the splitting point for each level of the tree.\n",
        "\n",
        "\n",
        "2. Using sklearn DecisionTreeClassifier library and compare the performance of the classifier against the method from scratch <font color='violet'>(try criterion = Gini and Entropy).</font> See (https://www.kaggle.com/code/hadibakhsh/decision-tree-play-tennis) for example."
      ],
      "metadata": {
        "id": "IM4ThUurz6cK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ClQ5RNIkz9mw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}